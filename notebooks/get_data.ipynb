{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SnP paper setting 2006 - 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  13 of 13 completed\n"
     ]
    }
   ],
   "source": [
    "# Sector ETF tickers representing the 11 S&P 500 sectors\n",
    "sector_tickers = [\n",
    "    \"XLF\",  # Financials\n",
    "    \"XLK\",  # Technology\n",
    "    \"XLV\",  # Health Care\n",
    "    \"XLY\",  # Consumer Discretionary\n",
    "    \"XLP\",  # Consumer Staples\n",
    "    \"XLE\",  # Energy\n",
    "    \"XLI\",  # Industrials\n",
    "    \"XLU\",  # Utilities\n",
    "    \"XLB\",  # Materials\n",
    "    \"XLRE\",  # Real Estate\n",
    "    \"XLC\",  # Communication Services\n",
    "]\n",
    "\n",
    "indices = [\n",
    "    \"^GSPC\",  # S&P 500\n",
    "    \"^VIX\",  # Volatility Index\n",
    "]\n",
    "\n",
    "# Date range from the paper\n",
    "start_date = \"1999-01-01\"\n",
    "end_date = \"2022-12-31\"\n",
    "\n",
    "freq = '1d'\n",
    "# freq = \"1mo\"\n",
    "\n",
    "# Download daily adjusted close prices for sector ETFs\n",
    "prices = yf.download(\n",
    "    sector_tickers + indices,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    interval=freq,\n",
    "    auto_adjust=True,\n",
    "    progress=True,\n",
    ")[\"Close\"]\n",
    "\n",
    "# Compute log returns for sector prices and S&P 500\n",
    "log_returns = np.log(prices / prices.shift(1))\n",
    "\n",
    "# Drop the first row NaNs\n",
    "log_returns = log_returns.dropna(axis=0, how=\"all\")\n",
    "\n",
    "# Calculate volatility metrics\n",
    "sp500_returns = prices[\"^GSPC\"].pct_change()  # simple returns\n",
    "vol20 = sp500_returns.rolling(20).std()\n",
    "vol60 = sp500_returns.rolling(60).std()\n",
    "vol_ratio = vol20 / vol60\n",
    "\n",
    "# Create df to hold vol metrics\n",
    "vol_df = pd.DataFrame(\n",
    "    {\n",
    "        \"vol20\": vol20,\n",
    "        \"vol60\": vol60,\n",
    "        \"vol_ratio\": vol_ratio,\n",
    "        \"VIX\": prices[\"^VIX\"],\n",
    "    }\n",
    ").iloc[60:]\n",
    "\n",
    "vol_df_std = vol_df.copy()\n",
    "# Standardize the metrics using expanding lookback window to prevent look-ahead bias\n",
    "for col in [\"vol20\", \"vol60\", \"vol_ratio\", \"VIX\"]:\n",
    "    mean = vol_df[col].expanding().mean()\n",
    "    std = vol_df[col].expanding().std()\n",
    "    vol_df_std[col] = (vol_df[col] - mean) / std\n",
    "\n",
    "# Drop the first row with NaN since there is no std yet\n",
    "vol_df_std = vol_df_std.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save SnP500 prices in a separate file\n",
    "save_dir = \"../data/snp\"\n",
    "prices[[\"^GSPC\"]].to_parquet(\n",
    "    f\"{save_dir}/prices_sp500_{freq}.parquet\", index=True, engine=\"pyarrow\"\n",
    ")\n",
    "prices[sector_tickers].to_parquet(\n",
    "    f\"{save_dir}/prices_{freq}.parquet\", index=True, engine=\"pyarrow\"\n",
    ")\n",
    "log_returns[sector_tickers].to_parquet(\n",
    "    f\"{save_dir}/returns_{freq}.parquet\", index=True, engine=\"pyarrow\"\n",
    ")\n",
    "vol_df_std[[\"vol20\", \"vol_ratio\", \"VIX\"]].to_parquet(\n",
    "    f\"{save_dir}/vola_{freq}.parquet\", index=True, engine=\"pyarrow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSCI country indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  8 of 8 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Canada    France   Germany     Italy     Japan  Switzerland  \\\n",
      "Date                                                                        \n",
      "2001-01-03  0.019138  0.019169  0.000000  0.045454  0.036765    -0.015190   \n",
      "2001-01-04  0.009389 -0.006269  0.000000 -0.048913 -0.028369     0.005141   \n",
      "2001-01-05 -0.018605 -0.009464  0.000000 -0.005714 -0.014598     0.000000   \n",
      "2001-01-08 -0.033175  0.000000 -0.002793  0.005747 -0.007408    -0.015345   \n",
      "2001-01-09  0.014706 -0.009554  0.002801 -0.005714 -0.022388    -0.007793   \n",
      "\n",
      "                  UK        US  \n",
      "Date                            \n",
      "2001-01-03  0.021053  0.048035  \n",
      "2001-01-04 -0.027492 -0.010764  \n",
      "2001-01-05  0.000000 -0.032643  \n",
      "2001-01-08  0.003534  0.007740  \n",
      "2001-01-09 -0.017606 -0.002641  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define tickers for major country ETFs or indices\n",
    "tickers = {\n",
    "    \"Canada\": \"EWC\",  # iShares MSCI Canada ETF\n",
    "    \"France\": \"EWQ\",  # iShares MSCI France ETF\n",
    "    \"Germany\": \"EWG\",  # iShares MSCI Germany ETF\n",
    "    \"Italy\": \"EWI\",  # iShares MSCI Italy ETF\n",
    "    \"Japan\": \"EWJ\",  # iShares MSCI Japan ETF\n",
    "    \"Switzerland\": \"EWL\",  # iShares MSCI Switzerland ETF\n",
    "    \"UK\": \"EWU\",  # iShares MSCI United Kingdom ETF\n",
    "    \"US\": \"SPY\",  # SPDR S&P 500 ETF Trust\n",
    "}\n",
    "\n",
    "# freq = '1mo'\n",
    "freq = \"1d\"\n",
    "\n",
    "# Download monthly adjusted close prices\n",
    "prices = yf.download(\n",
    "    list(tickers.values()),\n",
    "    start=\"2001-01-01\",\n",
    "    end=\"2021-12-31\",\n",
    "    interval=freq,\n",
    "    auto_adjust=True,\n",
    ")[\"Close\"]\n",
    "# Rename columns to country names\n",
    "prices.columns = tickers.keys()\n",
    "\n",
    "# Check for NaN in data and print\n",
    "# print(data.isna().sum())\n",
    "# display(data[data.isna().any(axis=1)])\n",
    "# data = data.dropna()\n",
    "\n",
    "# Calculate monthly returns\n",
    "returns = prices.pct_change().dropna()\n",
    "print(returns.head())\n",
    "\n",
    "path = \"../data/intl\"\n",
    "returns.to_parquet(f\"{path}/returns_{freq}.parquet\")\n",
    "prices.to_parquet(f\"{path}/prices_{freq}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    }
   ],
   "source": [
    "# get MSCI world for same timeframe and save separately\n",
    "prices = yf.download(\n",
    "    [\"^VIX\", \"^990100-USD-STRD\"],\n",
    "    start=\"2001-01-01\",\n",
    "    end=\"2021-12-31\",\n",
    "    interval=freq,\n",
    "    auto_adjust=True,\n",
    ")[\"Close\"]\n",
    "# rename to MSCI World\n",
    "prices.columns = [\"VIX\", \"MSCI World\"]\n",
    "prices[[\"MSCI World\"]].to_parquet(f\"{path}/prices_msci_{freq}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate volatility metrics\n",
    "msci_prices = prices[\"MSCI World\"].dropna()\n",
    "msci_returns = msci_prices.pct_change()  # simple returns\n",
    "\n",
    "vol20 = msci_returns.rolling(20).std()\n",
    "vol60 = msci_returns.rolling(60).std()\n",
    "vol_ratio = vol20 / vol60\n",
    "\n",
    "# Create df to hold vol metrics\n",
    "vol_df = pd.DataFrame(\n",
    "    {\n",
    "        \"vol20\": vol20,\n",
    "        \"vol60\": vol60,\n",
    "        \"vol_ratio\": vol_ratio,\n",
    "        \"VIX\": prices[\"VIX\"],\n",
    "    }\n",
    ").dropna(how=\"any\")\n",
    "\n",
    "vol_df_std = vol_df.copy()\n",
    "# Standardize the metrics using expanding lookback window to prevent look-ahead bias\n",
    "for col in [\"vol20\", \"vol60\", \"vol_ratio\", \"VIX\"]:\n",
    "    mean = vol_df[col].expanding().mean()\n",
    "    std = vol_df[col].expanding().std()\n",
    "    vol_df_std[col] = (vol_df[col] - mean) / std\n",
    "\n",
    "# Drop the first row with NaN since there is no std yet\n",
    "vol_df_std = vol_df_std.dropna(how=\"all\")\n",
    "vol_df = vol_df_std[[\"vol20\", \"vol_ratio\", \"VIX\"]]\n",
    "vol_df.to_parquet(f\"{path}/vola_{freq}.parquet\", index=True, engine=\"pyarrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
