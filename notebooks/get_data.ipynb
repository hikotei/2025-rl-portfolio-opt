{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  13 of 13 completed\n"
     ]
    }
   ],
   "source": [
    "# Sector ETF tickers representing the 11 S&P 500 sectors\n",
    "sector_tickers = [\n",
    "    \"XLF\",  # Financials\n",
    "    \"XLK\",  # Technology\n",
    "    \"XLV\",  # Health Care\n",
    "    \"XLY\",  # Consumer Discretionary\n",
    "    \"XLP\",  # Consumer Staples\n",
    "    \"XLE\",  # Energy\n",
    "    \"XLI\",  # Industrials\n",
    "    \"XLU\",  # Utilities\n",
    "    \"XLB\",  # Materials\n",
    "    \"XLRE\",  # Real Estate\n",
    "    \"XLC\",  # Communication Services\n",
    "]\n",
    "\n",
    "indices = [\n",
    "    \"^GSPC\",  # S&P 500\n",
    "    \"^VIX\",  # Volatility Index\n",
    "]\n",
    "\n",
    "# Date range from the paper\n",
    "start_date = \"2005-01-01\"\n",
    "end_date = \"2021-12-31\"\n",
    "\n",
    "freq = '1d'\n",
    "# freq = '1mo'\n",
    "\n",
    "# Download daily adjusted close prices for sector ETFs\n",
    "prices = yf.download(\n",
    "    sector_tickers + indices,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    interval=freq,\n",
    "    auto_adjust=True,\n",
    "    progress=True,\n",
    ")[\"Close\"]\n",
    "\n",
    "# Compute log returns for sector prices and S&P 500\n",
    "log_returns = np.log(prices / prices.shift(1))\n",
    "\n",
    "# Drop the first row NaNs\n",
    "log_returns = log_returns.dropna(axis=0, how=\"all\")\n",
    "\n",
    "# Calculate volatility metrics\n",
    "sp500_returns = prices[\"^GSPC\"].pct_change()  # simple returns\n",
    "vol20 = sp500_returns.rolling(20).std()\n",
    "vol60 = sp500_returns.rolling(60).std()\n",
    "vol_ratio = vol20 / vol60\n",
    "\n",
    "# Create df to hold vol metrics\n",
    "vol_df = pd.DataFrame(\n",
    "    {\n",
    "        \"vol20\": vol20,\n",
    "        \"vol60\": vol60,\n",
    "        \"vol_ratio\": vol_ratio,\n",
    "        \"VIX\": prices[\"^VIX\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "vol_df_std = vol_df.copy()\n",
    "# Standardize the metrics using expanding lookback window to prevent look-ahead bias\n",
    "for col in ['vol20', 'vol60', 'vol_ratio', 'VIX']:\n",
    "    mean = vol_df[col].expanding().mean()\n",
    "    std = vol_df[col].expanding().std()\n",
    "    vol_df_std[col] = (vol_df[col] - mean) / std\n",
    "\n",
    "# Drop the first row with NaN since there is no std yet\n",
    "vol_df_std = vol_df_std.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save SnP500 prices in a separate file\n",
    "prices[['^GSPC']].to_parquet(f'../data/snp_new/prices_sp500_{freq}.parquet', index=True, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices[sector_tickers].to_parquet(f'../data/snp_new/prices_{freq}.parquet', index=True, engine='pyarrow')\n",
    "log_returns[sector_tickers].to_parquet(f'../data/snp_new/returns_{freq}.parquet', index=True, engine='pyarrow')\n",
    "vol_df_std[['vol20', 'vol_ratio', 'VIX']].to_parquet(f'../data/snp_new/vola_{freq}.parquet', index=True, engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
