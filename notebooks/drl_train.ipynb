{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.portfolio_env import PortfolioEnv\n",
    "from utils.drl_agent import DRLAgent\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data (replace with actual paths) ---\n",
    "returns_df = pd.read_parquet(\"../data/returns.parquet\")\n",
    "prices_df = pd.read_parquet(\"../data/prices.parquet\")\n",
    "vol_df = pd.read_parquet(\"../data/vola.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data to just one year 2020 - 2021\n",
    "train_start = \"2006-01-01\"\n",
    "train_end = \"2006-06-01\"\n",
    "\n",
    "train_ret = returns_df[train_start:train_end]\n",
    "train_prices = prices_df[train_start:train_end]\n",
    "train_vol = vol_df[train_start:train_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create environment ---\n",
    "env = PortfolioEnv(\n",
    "    returns_df=train_ret,\n",
    "    prices_df=train_prices,\n",
    "    vol_df=train_vol,\n",
    "    window_size=60,\n",
    "    transaction_cost=0,\n",
    "    initial_balance=100_000,\n",
    "    reward_scaling=1.0,\n",
    "    eta=1 / 252,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = = = = = = \n",
    "# CHECK ENVIRONMENT\n",
    "# = = = = = = = = \n",
    "\n",
    "# from stable_baselines3.common.env_checker import check_env\n",
    "# check_env(env)\n",
    "\n",
    "# UserWarning: Your observation  has an unconventional shape (neither an image, nor a 1D vector). \n",
    "# We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
    "\n",
    "# UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \n",
    "# cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
    "\n",
    "# = = = = = = = = \n",
    "# RANDOM AGENT\n",
    "# = = = = = = = = \n",
    "\n",
    "# obs, info = env.reset()\n",
    "# n_steps = 1\n",
    "# for _ in range(n_steps):\n",
    "#     action = env.action_space.sample() # random action\n",
    "#     obs, reward, terminated, truncated, info = env.step(action)\n",
    "#     print(info)\n",
    "#     if terminated:\n",
    "#         obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dd4b6083f94b4aac236f2fc3d45507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanting/miniconda3/envs/rl/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 1260, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1512`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 252\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=756 and n_envs=2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = DRLAgent(\n",
    "    env,\n",
    "    model_name='ppo',\n",
    "    n_envs=2,\n",
    "    n_steps=756,\n",
    "    batch_size=1260,\n",
    "    n_epochs=16,\n",
    "    learning_rate=3e-4, # anneal to 1e-5\n",
    "    gamma=0.9,\n",
    "    gae_lambda=0.9,\n",
    "    clip_range=0.25\n",
    ")\n",
    "\n",
    "agent.train(total_timesteps=100)\n",
    "agent.save(\"../models/ppo_portfolio.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data to just one year 2020 - 2021\n",
    "eval_start = \"2021-01-01\"\n",
    "eval_end = \"2021-06-01\"\n",
    "\n",
    "eval_ret = returns_df[eval_start:eval_end]\n",
    "eval_prices = prices_df[eval_start:eval_end]\n",
    "eval_vol = vol_df[eval_start:eval_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating DRL agent...\n",
      "\n",
      "Evaluation Summary:\n",
      "Final Portfolio Value: $105,837.80\n",
      "Average Reward: -6.3146\n",
      "\n",
      "Performance Metrics:\n",
      "Annual return: 0.4003\n",
      "Cumulative returns: 0.0577\n",
      "Annual volatility: 0.1059\n",
      "Sharpe ratio: 3.1219\n",
      "Calmar ratio: 12.0271\n",
      "Stability: 0.9042\n",
      "Max drawdown: -0.0333\n",
      "Omega ratio: 1.6567\n",
      "Sortino ratio: 4.4589\n",
      "Skew: -0.6244\n",
      "Kurtosis: 0.6658\n",
      "Tail ratio: 1.0783\n",
      "Daily value at risk: -0.0091\n",
      "Portfolio turnover: 0.0053\n",
      "Average Reward: -6.3146\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate DRL agent ---\n",
    "# Create evaluation environment\n",
    "eval_env = PortfolioEnv(\n",
    "    returns_df=eval_ret,\n",
    "    prices_df=eval_prices,\n",
    "    vol_df=eval_vol,\n",
    "    window_size=60,\n",
    "    transaction_cost=0,\n",
    "    initial_balance=100_000,\n",
    "    reward_scaling=1.0,\n",
    "    eta=1 / 252,\n",
    ")\n",
    "\n",
    "# Evaluate DRL agent\n",
    "print(\"Evaluating DRL agent...\")\n",
    "drl_metrics = agent.evaluate(eval_env, n_episodes=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
