{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dataclasses import asdict\n",
    "\n",
    "from datetime import datetime\n",
    "from utils.config import DRLConfig\n",
    "from utils.drl_train import training_pipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/snp_new\"\n",
    "RETURNS_PATH = os.path.join(DATA_DIR, \"returns_1d.parquet\")\n",
    "PRICES_PATH = os.path.join(DATA_DIR, \"prices_1d.parquet\")\n",
    "VOLA_PATH = os.path.join(DATA_DIR, \"vola_1d.parquet\")\n",
    "\n",
    "# DATA_DIR = \"../data/intl\"\n",
    "# RETURNS_PATH = os.path.join(DATA_DIR, \"returns_1d.parquet\")\n",
    "# PRICES_PATH = os.path.join(DATA_DIR, \"prices_1d.parquet\")\n",
    "# VOLA_PATH = os.path.join(DATA_DIR, \"vola_1d.parquet\")\n",
    "\n",
    "df_ret = pd.read_parquet(RETURNS_PATH)\n",
    "df_prices = pd.read_parquet(PRICES_PATH)\n",
    "df_vol = pd.read_parquet(VOLA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the logs:\n",
    "# 1. Open a terminal or command prompt.\n",
    "# 2. Navigate to the directory *containing* the `logs` directory (i.e., the root of this repository).\n",
    "# 3. Run the command: `tensorboard --logdir logs/`\n",
    "# 4. Open the URL provided by TensorBoard (usually http://localhost:6006/) in your web browser.\n",
    "\n",
    "# Create timestamp for this run\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "N_WINDOWS       = 10 # 10 in paper\n",
    "N_AGENTS        = 5 # 5 in paper\n",
    "START_YR        = 2006 # 2006 in paper\n",
    "TOTAL_STEPS     = 7_500_000 # 7_500_000 in paper\n",
    "SEED_POLICY     = True \n",
    "FOLDER_NAME     = f\"{timestamp}_train_start={START_YR}_best_seed={SEED_POLICY}\"\n",
    "\n",
    "# Create configuration\n",
    "config = DRLConfig(\n",
    "    # Window configuration\n",
    "    n_windows=N_WINDOWS,  \n",
    "    agents_per_window=N_AGENTS,  \n",
    "    base_start_year=START_YR,  \n",
    "    seed_policy=SEED_POLICY,\n",
    "    # Environment parameters\n",
    "    env_window_size=60,\n",
    "    transaction_cost=0.0,\n",
    "    initial_balance=100_000,\n",
    "    reward_scaling=1.0,\n",
    "    eta_dsr=1 / 252,\n",
    "    # Training parameters\n",
    "    n_envs=10,\n",
    "    total_timesteps_per_round=TOTAL_STEPS,\n",
    "    n_steps_per_env=252 * 3,\n",
    "    batch_size=1260,\n",
    "    n_epochs=16,\n",
    "    gamma=0.9,\n",
    "    gae_lambda=0.9,\n",
    "    clip_range=0.25,\n",
    "    log_std_init=-1.0,\n",
    "    # Learning rate parameters\n",
    "    initial_lr=3e-4,\n",
    "    final_lr=1e-5,\n",
    "    # Paths\n",
    "    model_save_dir=f\"../models/{FOLDER_NAME}\",\n",
    "    tensorboard_log_dir=f\"../logs/{FOLDER_NAME}\",\n",
    "    data_dir=DATA_DIR,\n",
    ")\n",
    "\n",
    "config_dict = asdict(config)\n",
    "config_json_path = os.path.join(config.model_save_dir, f\"config_{timestamp}.json\")\n",
    "os.makedirs(config.model_save_dir, exist_ok=True)\n",
    "with open(config_json_path, \"w\") as f:\n",
    "    json.dump(config_dict, f, indent=4)\n",
    "print(f\"\\nConfiguration saved to: {config_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training pipeline\n",
    "results, backtest_portfolio = training_pipeline(\n",
    "    drl_config=config, df_prices=df_prices, df_ret=df_ret, df_vol=df_vol\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, p in backtest_portfolio.items():\n",
    "    fname = f\"{idx}_portfolio.csv\"\n",
    "    p.get_history().to_csv(os.path.join(config.model_save_dir, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filename = f\"backtest_results_summary_{timestamp}.csv\"\n",
    "results_save_path = os.path.join(config.model_save_dir, results_filename)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(results_save_path, index=False)\n",
    "print(f\"\\nBacktest results summary saved to: {results_save_path}\")\n",
    "print(\"\\nFinal Results DataFrame:\")\n",
    "results_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
