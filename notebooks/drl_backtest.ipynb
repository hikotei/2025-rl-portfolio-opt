{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78622dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.drl_train import (\n",
    "    generate_sliding_windows,\n",
    "    train_agents,\n",
    "    select_best_agent,\n",
    "    backtest_all_agents\n",
    ")\n",
    "from utils.portfolio_env_old import PortfolioEnv\n",
    "from utils.drl_agent import DRLAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbfeba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load your data ---\n",
    "returns_df = pd.read_parquet(\"../data/returns.parquet\")\n",
    "prices_df = pd.read_parquet(\"../data/prices.parquet\")\n",
    "vol_df = pd.read_parquet(\"../data/vola.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9362a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window: {'train': ('2006-01-01', '2011-01-01'), 'val': ('2011-01-01', '2012-01-01'), 'test': ('2012-01-01', '2013-01-01')}\n"
     ]
    }
   ],
   "source": [
    "# --- Pick the first sliding window: 2006â€“2012 (train), 2011 (val), 2012 (test) ---\n",
    "window = list(generate_sliding_windows(2006, 2021))[0]\n",
    "print(\"Window:\", window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ac7cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NaN values in observation at step 60",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Train 5 agents ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m agents = \u001b[43mtrain_agents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDRLAgent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPortfolioEnv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturns_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprices_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvol_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_seeds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# --- Select best agent based on Sharpe in validation year ---\u001b[39;00m\n\u001b[32m      5\u001b[39m best_agent = select_best_agent(agents, PortfolioEnv, returns_df, prices_df, vol_df, window)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/2025-rl-portfolio-opt/utils/drl_train.py:46\u001b[39m, in \u001b[36mtrain_agents\u001b[39m\u001b[34m(DRLAgent, PortfolioEnv, returns_df, prices_df, vol_df, window, n_seeds, total_timesteps)\u001b[39m\n\u001b[32m     43\u001b[39m train_vol = vol_df[window[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m]:window[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m1\u001b[39m]]\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_seeds):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     train_env = \u001b[43mmake_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPortfolioEnv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_returns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_vol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     agent = DRLAgent(\n\u001b[32m     49\u001b[39m         env=train_env,\n\u001b[32m     50\u001b[39m         model_name=\u001b[33m'\u001b[39m\u001b[33mppo\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m         clip_range=\u001b[32m0.25\u001b[39m,\n\u001b[32m     59\u001b[39m     )\n\u001b[32m     60\u001b[39m     agent.train(total_timesteps=total_timesteps, seed=seed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/2025-rl-portfolio-opt/utils/drl_train.py:24\u001b[39m, in \u001b[36mmake_env\u001b[39m\u001b[34m(PortfolioEnv, returns, prices, vol)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_env\u001b[39m(PortfolioEnv, returns, prices, vol):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    Constructs a PortfolioEnv instance from data slices.\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPortfolioEnv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturns_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprices_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvol_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransaction_cost\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43minitial_balance\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreward_scaling\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43meta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m252\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/2025-rl-portfolio-opt/utils/portfolio_env_old.py:84\u001b[39m, in \u001b[36mPortfolioEnv.__init__\u001b[39m\u001b[34m(self, returns_df, prices_df, vol_df, window_size, transaction_cost, initial_balance, reward_scaling, eta)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28mself\u001b[39m.observation_space = spaces.Box(\n\u001b[32m     74\u001b[39m     low=-np.inf,\n\u001b[32m     75\u001b[39m     high=np.inf,\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     dtype=np.float32,\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Initialize state\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/2025-rl-portfolio-opt/utils/portfolio_env_old.py:111\u001b[39m, in \u001b[36mPortfolioEnv.reset\u001b[39m\u001b[34m(self, seed)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mself\u001b[39m.prev_B_t = \u001b[32m0.0\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m.prev_sharpe = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/2025-rl-portfolio-opt/utils/portfolio_env_old.py:197\u001b[39m, in \u001b[36mPortfolioEnv._get_observation\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Check for NaN values\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.isnan(observation).any():\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNaN values in observation at step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.current_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m observation.astype(np.float32)\n",
      "\u001b[31mValueError\u001b[39m: NaN values in observation at step 60"
     ]
    }
   ],
   "source": [
    "# --- Train 5 agents ---\n",
    "agents = train_agents(DRLAgent, PortfolioEnv, returns_df, prices_df, vol_df, window, n_seeds=5)\n",
    "\n",
    "# --- Select best agent based on Sharpe in validation year ---\n",
    "best_agent = select_best_agent(agents, PortfolioEnv, returns_df, prices_df, vol_df, window)\n",
    "\n",
    "# --- Backtest all 5 agents on the test year (2012) ---\n",
    "all_metrics = backtest_all_agents(agents, PortfolioEnv, returns_df, prices_df, vol_df, window)\n",
    "\n",
    "# --- Summarize Results ---\n",
    "def summarize_metrics(metrics_list):\n",
    "    summary = {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    for key in keys:\n",
    "        values = [m[key] for m in metrics_list]\n",
    "        if isinstance(values[0], (int, float)):\n",
    "            summary[key] = {\n",
    "                \"mean\": np.mean(values),\n",
    "                \"std\": np.std(values)\n",
    "            }\n",
    "    return summary\n",
    "\n",
    "summary = summarize_metrics(all_metrics)\n",
    "\n",
    "print(\"\\nðŸ“Š Aggregated Evaluation Metrics (Mean Â± Std over 5 agents):\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v['mean']:.4f} Â± {v['std']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
