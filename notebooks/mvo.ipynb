{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb99a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "import pypfopt.objective_functions as objective_functions\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.efficient_frontier import EfficientFrontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe127732",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_tickers = [\n",
    "    \"XLF\",  # Financials\n",
    "    \"XLK\",  # Technology\n",
    "    \"XLV\",  # Health Care\n",
    "    \"XLY\",  # Consumer Discretionary\n",
    "    \"XLP\",  # Consumer Staples\n",
    "    \"XLE\",  # Energy\n",
    "    \"XLI\",  # Industrials\n",
    "    \"XLU\",  # Utilities\n",
    "    \"XLB\",  # Materials\n",
    "    \"XLRE\",  # Real Estate\n",
    "    \"XLC\",  # Communication Services\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb2030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from csv\n",
    "df_ret = pd.read_parquet(\"../data/returns.parquet\")\n",
    "df_prices = pd.read_parquet(\"../data/prices.parquet\")\n",
    "df_vol = pd.read_parquet(\"../data/vola.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cec16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE : deal with NaN values for tickers\n",
    "# XLC was created June 2018\n",
    "# XLRE was created Oct 2015 ( as split off from XLF )\n",
    "# so during training, check if any of the tickers are NaN\n",
    "# if yes then set their weight to 0 and dont include them for cov mat and optimization\n",
    "\n",
    "# DONE : understand why solver sometimes fails\n",
    "# maybe write own solver\n",
    "# maybe eigenvals too small therefore unstable\n",
    "# why does mu < riskfree rate lead to problems ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d4353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date 2019-01-01 00:00:00 not in data, skipping.\n",
      "All expected returns are negative for 2019-01-03 00:00:00\n",
      "All expected returns are negative for 2019-01-04 00:00:00\n",
      "All expected returns are negative for 2019-01-07 00:00:00\n",
      "All expected returns are negative for 2019-01-08 00:00:00\n",
      "Date 2019-01-21 00:00:00 not in data, skipping.\n",
      "Date 2019-02-18 00:00:00 not in data, skipping.\n",
      "Date 2019-04-19 00:00:00 not in data, skipping.\n",
      "Date 2019-05-27 00:00:00 not in data, skipping.\n",
      "Date 2019-07-04 00:00:00 not in data, skipping.\n",
      "Date 2019-09-02 00:00:00 not in data, skipping.\n",
      "Date 2019-11-28 00:00:00 not in data, skipping.\n",
      "Date 2019-12-25 00:00:00 not in data, skipping.\n",
      "Date 2020-01-01 00:00:00 not in data, skipping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cash</th>\n",
       "      <th>portfolio_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>287.006510</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>347.556498</td>\n",
       "      <td>98172.411026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>245.380980</td>\n",
       "      <td>101204.601385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>228.984713</td>\n",
       "      <td>101890.654400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>279.667929</td>\n",
       "      <td>102960.902676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>364.952177</td>\n",
       "      <td>127947.972797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>347.236746</td>\n",
       "      <td>128495.880484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>336.457146</td>\n",
       "      <td>128471.505199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>221.936064</td>\n",
       "      <td>127906.519566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>234.883104</td>\n",
       "      <td>128324.860144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        cash  portfolio_value\n",
       "0   2019-01-02  287.006510    100000.000000\n",
       "1   2019-01-03  347.556498     98172.411026\n",
       "2   2019-01-04  245.380980    101204.601385\n",
       "3   2019-01-07  228.984713    101890.654400\n",
       "4   2019-01-08  279.667929    102960.902676\n",
       "..         ...         ...              ...\n",
       "247 2019-12-24  364.952177    127947.972797\n",
       "248 2019-12-26  347.236746    128495.880484\n",
       "249 2019-12-27  336.457146    128471.505199\n",
       "250 2019-12-30  221.936064    127906.519566\n",
       "251 2019-12-31  234.883104    128324.860144\n",
       "\n",
       "[252 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean variance optimization\n",
    "# based on paper by Sood et al. (2023):\n",
    "\n",
    "# Parameters\n",
    "lookback = 60\n",
    "initial_cash = 100_000\n",
    "start_date = pd.to_datetime(\"2019-01-01\")\n",
    "end_date = pd.to_datetime(\"2020-01-01\")\n",
    "\n",
    "# define daterange from start to end date\n",
    "date_range = pd.bdate_range(start=start_date, end=end_date)\n",
    "\n",
    "# Initialize portfolio\n",
    "portfolio_value = initial_cash\n",
    "portfolio_history = []\n",
    "\n",
    "cash = initial_cash\n",
    "shares = {t: 0 for t in sector_tickers}\n",
    "\n",
    "for eval_date in date_range:\n",
    "    if eval_date not in df_ret.index:\n",
    "        print(f\"Date {eval_date} not in data, skipping.\")\n",
    "        continue\n",
    "\n",
    "    ret_idx = df_ret.index.get_loc(eval_date)\n",
    "    prices_idx = df_prices.index.get_loc(eval_date)\n",
    "\n",
    "    if ret_idx < lookback:\n",
    "        print(f\"Not enough data for {eval_date}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    return_window = df_ret.iloc[ret_idx - lookback : ret_idx]\n",
    "    prices_window = df_prices.iloc[prices_idx - lookback : prices_idx]\n",
    "\n",
    "    nan_tickers = []\n",
    "    for ticker in sector_tickers:\n",
    "        if return_window[ticker].isna().any():\n",
    "            nan_tickers.append(ticker)\n",
    "\n",
    "    if len(nan_tickers) > 0:\n",
    "        print(f\"NaN values for {eval_date}: {nan_tickers}\")\n",
    "        return_window = return_window.drop(columns=nan_tickers)\n",
    "        prices_window = prices_window.drop(columns=nan_tickers)\n",
    "        valid_sectors = [t for t in sector_tickers if t not in nan_tickers]\n",
    "    else:\n",
    "        valid_sectors = sector_tickers\n",
    "\n",
    "    # update portfolio value with current prices\n",
    "    prices = df_prices.iloc[prices_idx].to_dict()\n",
    "    if len(portfolio_history) > 0:\n",
    "        portfolio_value = sum([shares[t] * prices[t] for t in valid_sectors]) + cash\n",
    "\n",
    "    # Estimate covariance using Ledoit-Wolf shrinkage\n",
    "    lw = LedoitWolf()\n",
    "    lw.fit(return_window)\n",
    "    cov_matrix = lw.covariance_\n",
    "\n",
    "    # Fix potential negative eigenvalues (make PSD)\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n",
    "    eigvals[eigvals < 0] = 0\n",
    "    cov_psd = eigvecs @ np.diag(eigvals) @ eigvecs.T\n",
    "\n",
    "    # estimate expected returns over lookback period as simple average\n",
    "    mu = return_window.mean()\n",
    "    # check if all of mu are below 0, if yes report error\n",
    "    if (mu < 0).all():\n",
    "        print(f\"All expected returns are negative for {eval_date}\")\n",
    "        # continue\n",
    "\n",
    "    # NOTE on negative expected returns :\n",
    "    # (https://github.com/robertmartin8/PyPortfolioOpt/issues/88#issuecomment-615533265)\n",
    "    # you should think about whether your expected returns are a good estimate of future returns\n",
    "    # if they aren't, then the max_sharpe portfolio will be pretty useless!\n",
    "\n",
    "    # Calculate optimal weights by optimizing Sharpe ratio\n",
    "    ef = EfficientFrontier(mu, cov_psd)\n",
    "\n",
    "    # ALTERNATIVE #1 using max_sharpe\n",
    "    # try:\n",
    "    #     weights_raw = ef.max_sharpe(risk_free_rate=0)  # ordered dict\n",
    "    # except Exception as e:\n",
    "    #     # error probably because the optimisation problem is not convex\n",
    "    #     print(\"= \" * 20)\n",
    "    #     print(f\"Error in max_sharpe for {eval_date}: {e}\")\n",
    "    #     print(\"mu\", mu)\n",
    "    #     print(\"cov_psd\", cov_psd)\n",
    "    #     print(\"eigvals\", eigvals)\n",
    "    #     print(\"= \" * 20)\n",
    "    #     continue\n",
    "\n",
    "    # ALTERNATIVE #2 ( see https://github.com/robertmartin8/PyPortfolioOpt/issues/88 )\n",
    "    w_min, w_max = 0, 1\n",
    "    weights_raw = ef.nonconvex_objective(\n",
    "        objective_functions.sharpe_ratio,\n",
    "        objective_args=(ef.expected_returns, ef.cov_matrix),\n",
    "        constraints=[\n",
    "            {\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1}, # sum to 1\n",
    "            {\"type\": \"ineq\", \"fun\": lambda w: w - w_min,}, # larger than min\n",
    "            {\"type\": \"ineq\", \"fun\": lambda w: w_max - w}, # smaller than max\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # whole shares only\n",
    "    asset_cash = {t: weights_raw[t] * portfolio_value for t in valid_sectors}\n",
    "    shares = {t: np.floor(asset_cash[t] / prices[t]) for t in valid_sectors}\n",
    "    # calc rebalanced weights to compare with DRL agents later\n",
    "    weights = {t: shares[t] * prices[t] / portfolio_value for t in valid_sectors}\n",
    "    # rest ist cash\n",
    "    cash = portfolio_value - np.sum([shares[t] * prices[t] for t in valid_sectors])\n",
    "    w_c = cash / portfolio_value\n",
    "\n",
    "    # save portfolio history\n",
    "    portfolio_history.append(\n",
    "        {\"date\": eval_date, \"cash\": cash, \"portfolio_value\": portfolio_value}\n",
    "    )\n",
    "\n",
    "# Convert to DataFrame\n",
    "portfolio_df = pd.DataFrame(portfolio_history)\n",
    "portfolio_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
